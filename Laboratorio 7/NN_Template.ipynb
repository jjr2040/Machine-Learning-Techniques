{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcestevezc/Machine-Learning-Techniques/blob/master/Laboratorio%207/NN_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ffxRZZbhIP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://cursos.virtual.uniandes.edu.co/isis4219/wp-content/uploads/sites/162/2014/11/cropped-misisheader.png\" ><br>\n",
        "# Machine Learning Techniques - ISIS4219\n",
        "\n",
        "Intersemestral 2020\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhQ10uguL5Sb",
        "colab_type": "text"
      },
      "source": [
        "## Nombre de la red\n",
        "\n",
        "¿Que es una red XXXX?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLzkSAOwMGiH",
        "colab_type": "text"
      },
      "source": [
        "### **1. Razones para utilizar la red**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwIEEATzMGo3",
        "colab_type": "text"
      },
      "source": [
        "### **2. Aplicaciones de la red**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ntZZmGMGsb",
        "colab_type": "text"
      },
      "source": [
        "### **3. Arquitectura de la red**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEE5BsveMGvp",
        "colab_type": "text"
      },
      "source": [
        "### **4. La red en Keras**\n",
        "\n",
        "Keras no tiene una Echo State Network (ESN) implementada por defecto. Lo que sí se puede hacer es crear una celda personalizada para después utilizarla. A continuación se muestra una implementación encontrada en https://github.com/francesco-mannella/Echo-State-Networks/tree/master. Lo que hace es crear una celda personalizada y con ella construir las capas de una red neuronal recurrente (RNN). Al final, le agrega una última capa de salida densa que normalmente se le llama *readouts*. La implementación de la celda ESN la pueden encontrar en el siguiente link: https://github.com/francesco-mannella/Echo-State-Networks/blob/master/ESN.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init the ESN cell\n",
        "cell = EchoStateRNNCell(units=num_units, \n",
        "                        activation=activation, \n",
        "                        decay=0.1, \n",
        "                        epsilon=1e-20,\n",
        "                        alpha=0.5,\n",
        "                        optimize=True,\n",
        "                        optimize_vars=[\"rho\", \"decay\", \"alpha\", \"sw\"],\n",
        "                        seed=random_seed)\n",
        "\n",
        "# Build the recurrent layer containing the ESN cell\n",
        "recurrent_layer = keras.layers.RNN(cell, input_shape=(stime, num_inputs), \n",
        "                                   return_sequences=True, name=\"nn\")\n",
        "# Build the readout layer\n",
        "output = keras.layers.Dense(num_outputs, name=\"readouts\")\n",
        "# initialize the adam optimizer for training\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# put all together in a keras sequential model\n",
        "model = keras.models.Sequential()\n",
        "model.add(recurrent_layer)\n",
        "model.add(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay un proyecto muy popular llamado pyESN (https://github.com/anvien/PyESN) que también nos podría servir como alternativa. Este es desarrollado en python, sin utilizar keras, tensorflow, o ninguna otra librería a parte de numpy y matplotlib. En el siguiente proyecto, se encuentra una implementación en la que se combina una versión modificada de pyESN y keras para formar la ESN completa: https://github.com/cknd/pyESN/pull/6/commits/55cb273591748665f33db5d5052bb31b08e95009. La manera que se usa es la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import unittest\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from pyESN import ESN\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=200, activation='relu', input_dim=N+N_in))\n",
        "model.add(keras.layers.Dense(units=N_out, activation='linear'))\n",
        "model.compile(loss='mae', optimizer='adagrad')\n",
        "\n",
        "esn = ESN(N_in, N_out, n_reservoir=N, keras_model=model)\n",
        "esn.fit(self.X, self.y, epochs=20, verbose=0)\n",
        "esn.predict(self.Xp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSP8Av50MG34",
        "colab_type": "text"
      },
      "source": [
        "### **5. Propiedades e hiperparametros**\n",
        "\n",
        "Para el primer caso, los hiperparámetros para una ESN son los siguientes:\n",
        "\n",
        "* units (int): Número de unidades de la celda RNN\n",
        "* decay (float): Deterioro (decay) de la ODE de cada unidad. Default: 0.1.\n",
        "* seed (int): Semilla para los números aleatorios. Default None.\n",
        "* epsilon (float): Descuento al radio spectral de 1. Default: 1e-10.\n",
        "* alpha (float): [0,1], la proporsión infinitesimal de expansión vs la rotación infinitesimal de un sistema dunámico definido por sus pesos internos\n",
        "* sparseness (float): [0,1], Qué tan espacidos están los pesos de la matriz interna Default: 0.\n",
        "* rho (float): Escala de los pesos internos\n",
        "* sw (float): Escala de los pesos de entrada\n",
        "* activation (callable): Función de activación a usar  Default: `tanh`.\n",
        "\n",
        "Referencia: Tomado de https://github.com/francesco-mannella/Echo-State-Networks/blob/master/ESN.py#L39"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para el segundo caso, que utiliza pyESN, los hiperparámetros son los siguientes:\n",
        "\n",
        "* n_inputs: Dimensión de entrada.\n",
        "* n_outputs: Dimensión de salida.\n",
        "* n_reservoir: Número de neuronas en el reservoir.\n",
        "* spectral_radius: Radio espectral de la matriz de pesos recurrente.\n",
        "* sparsity: Proporción de los pesos recurrentes con valos cero.\n",
        "* noise: Ruido agregado a cada neurona (Regularización).\n",
        "* input_shift: Escalar o vector del tamaño de n_inputs a agregar a cada dimensión antes de alimentar la red.\n",
        "* input_scaling: Escalar o vector del tamaño de n_inputs a multiplicar con cada dimensión de entrada antes de alimentar la red.\n",
        "* teacher_forcing: Si True, alimentar el target de vuelta a las unidades de salida.\n",
        "* teacher_scaling: Factor aplicado a la señal de target.\n",
        "* teacher_shift: Término aditivo aplicado a la señal target.\n",
        "* keras_model: Entrenado para mapear la salida. input_size debe ser n_reservoir+1; output_size debe ser del mismo tamaño que n_outputs. Llamar `compile` en el modelo antes de pasarlo como parámetro.\n",
        "* out_activation: Función de activación de la capa de salida.\n",
        "* inverse_out_activation: Inversa de la función de la capa de salida.\n",
        "* random_state: semilla.\n",
        "\n",
        "Referencia: Tomado de https://github.com/cknd/pyESN/pull/6/commits/55cb273591748665f33db5d5052bb31b08e95009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UTi20gZbNIok"
      },
      "source": [
        "### **6. Ejemplo practico - Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbxDnwb8NaNo",
        "colab_type": "text"
      },
      "source": [
        "Nota: para el desarrollo de este taller, tomar como referencia el siguiente ejemplo: [autoencoders](https://www.edureka.co/blog/autoencoders-tutorial/)."
      ]
    }
  ]
}